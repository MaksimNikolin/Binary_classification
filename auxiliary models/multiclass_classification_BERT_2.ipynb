{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.tsv', sep='\\t')\n",
        "df_test = pd.read_csv('test.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "PF6qRSjM-5F7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut87PGK2-5DH",
        "outputId": "b75afb1b-b423-4373-c8ca-f5d40db222c4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=0.3)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWBu3RtaCLVA",
        "outputId": "e59bbc0a-e27c-441d-9ba4-45a183519037"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46818, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "seq_len = 256\n",
        "num_samples = len(df)\n",
        "\n",
        "Xids = np.zeros((num_samples, seq_len))\n",
        "Xmask = np.zeros((num_samples, seq_len))\n",
        "\n",
        "Xids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-1rDYCe-5BQ",
        "outputId": "c225fc9f-c2a1-44c4-cf70-59e2885e3ecd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46818, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "BBvGsL2MM9l_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "for i, phrase in enumerate(df['Phrase']):\n",
        "  tokens = tokenizer.encode_plus(phrase, max_length=seq_len, truncation=True,\n",
        "                                 padding='max_length', add_special_tokens=True,\n",
        "                                 return_tensors='tf')\n",
        "\n",
        "  Xids[i, :] = tokens['input_ids']\n",
        "  Xmask[i, :] = tokens['attention_mask']"
      ],
      "metadata": {
        "id": "T_rNZweK-4_8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = df['Sentiment'].values"
      ],
      "metadata": {
        "id": "f_ukZtBc-48p"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.zeros((num_samples, arr.max()+1))"
      ],
      "metadata": {
        "id": "AeZAb-FM-46C"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "h2ygJ7Q3-430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be75096e-7ccc-4cd3-8056-98cb74f3c5d2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46818, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[np.arange(num_samples), arr] = 1"
      ],
      "metadata": {
        "id": "zkh4JB65-41W"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "RwDU_oUi-4xJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
        "dataset"
      ],
      "metadata": {
        "id": "zNeVZGnx-4u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff27b66-33f5-4911-cac3-a0510ecbb7b9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids' : input_ids, 'attention_mask' : masks}, labels"
      ],
      "metadata": {
        "id": "nihVHYlx-4oV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(map_func)\n",
        "dataset"
      ],
      "metadata": {
        "id": "xXQ4YBj9-4mB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6340d148-767f-4fa5-ea62-7fc84c3b3b1a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_ids': TensorSpec(shape=(256,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(256,), dtype=tf.float64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "\n",
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "tzlvhpvc-4hY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d775914f-1f0b-4f12-d2d0-a0955b9f6aed"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = 0.9\n",
        "size = int((num_samples / batch_size) * split)"
      ],
      "metadata": {
        "id": "3HNkGilR-4dX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = dataset.take(size)\n",
        "val_ds = dataset.skip(size)"
      ],
      "metadata": {
        "id": "38b3Bzam-4a4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "pBkun1tGm5Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "bert = TFAutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "bert.summary()"
      ],
      "metadata": {
        "id": "M9NDuAN3-4Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c2d471-d001-4cb5-aa67-7e7806c07034"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,482,240\n",
            "Trainable params: 109,482,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
        "\n",
        "embeddings = bert.bert(input_ids, attention_mask=mask)[1]\n",
        "\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
        "y = tf.keras.layers.Dense(arr.max()+1, activation='softmax', name='outputs')(x)"
      ],
      "metadata": {
        "id": "YE2byOKO-4Ub"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "\n",
        "model.layers[2].trainable=False\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "17d61oAp-4SM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0436dbc-ae39-4bf8-898c-4b3d086b88fd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1024)         787456      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 5)            5125        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,274,821\n",
            "Trainable params: 792,581\n",
            "Non-trainable params: 109,482,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, weight_decay=1e-6)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
      ],
      "metadata": {
        "id": "LrOZvhLx-4Pt"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
      ],
      "metadata": {
        "id": "NaVE8jC7-4Ni"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=1)"
      ],
      "metadata": {
        "id": "9keAQMTW-4LI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c5dc1c-2738-472a-a8a0-476b494ada39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  97/2633 [>.............................] - ETA: 14:43:32 - loss: 1.3375 - accuracy: 0.4910"
          ]
        }
      ]
    }
  ]
}